{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-1: Split the data intro train and test (check the eda notebook to see the data).\n",
    "### Step-2: Take out 10% of the training data as a small labeled data to evaluate the efficiency of self-supervised learning.\n",
    "### Step-3: train on this small labeled data and compute the results on test data\n",
    "### Step-4: Do self-supervised learning on entire training data without using their labels\n",
    "### Step-5: use the pretrained rotnet model and fine tune on the small labeled data \n",
    "### Step-6: use the above finetuned model and evaluate the perfromance on test data.\n",
    "### Step-7: Compare the test results from step-3 with step-6 to see the benefits of unsupervised/self-supervised pretraining\n",
    "\n",
    "### --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) see the notebook preparing_labeled_train_test_csv_files.ipynb\n",
    "### b) 60 random flowers for each 5 flower category is taken as test data totaling to 300 test samples\n",
    "### c) The EDA for different flowers distribution in each train and test category is at EDA_Flowers.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) 10% of the train data is taken to be used as small labeled data.\n",
    "### b) This data is prepared by taking 10% of from each flower category.\n",
    "### c) The code for this is available at prepare_small_labeled_data.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Prepare a dataloader for loading data\n",
    "### b) Preapare a config file\n",
    "### c) We will be using off-the-shelf ResNet-18 model\n",
    "### d) Train the model and record the results in logfile as well as tensorboard\n",
    "### e) Choose the best checkpoint and compute the result on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-4 \n",
    "### a) prepare dataloader for rotnet\n",
    "### b) prepare config file for self-supervised learning\n",
    "### c) Train the model with self-supervised task/proxy labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-5\n",
    "### a) Use the pretrained rotnet model by removing last layer and adding new layer for flower classification task\n",
    "### b) Freeze the old layers to preserve the feature learned during unsupervised pretraining\n",
    "### c) Fine tune the model for the flower classification task with small labeled data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-6\n",
    "### a)use the above finetuned model and evaluate the perfromance on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-7\n",
    "### a)Compare the test results from step-3 with step-6 to see the benefits of unsupervised/self-supervised pretraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## supervised training on small labeled data \n",
    "#Parameters for supervised training\n",
    "#network: 'resnet18'\n",
    "#lr: 1e-3\n",
    "#momentum: 9e-1\n",
    "#scheduler: False\n",
    "#opt: 'adam'\n",
    "\n",
    "#num_epochs: 250\n",
    "#batch_size: 16\n",
    "#mean_norm: False\n",
    "#img_sz: 128\n",
    "#val_split: 0.15\n",
    "#cuda_num: 3\n",
    "#use_cuda: True\n",
    "#data_aug: True #['randomhorizontalflip','randomcrop']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name='sl_pytorch_exp_1_small'\n",
    "logs=os.path.join('experiments\\supervised',experiment_name,'tboard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir tboard (started 0:04:41 ago; pid 10344)\n",
      "  - port 6012: logdir tboard (started 0:01:16 ago; pid 10904)\n",
      "  - port 6006: logdir D:2020Trainingsself_supervised_learningexperimentssupervisedsl_pytorch_exp_1_smalllogs (started 0:07:38 ago; pid 20088)\n",
      "  - port 6006: logdir tboard (started 0:02:36 ago; pid 21672)\n",
      "  - port 6006: logdir logs (started 0:09:42 ago; pid 4672)\n",
      "  - port 6006: logdir D:2020Trainingsself_supervised_learningexperimentssupervisedsl_pytorch_exp_1_smalltboard (started 0:07:20 ago; pid 5340)\n"
     ]
    }
   ],
   "source": [
    "from tensorboard import notebook\n",
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting TensorBoard with logdir tboard (started 0:01:51 ago; port 6012, pid 10904).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6eee24cc222a629d\" width=\"100%\" height=\"1000\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6eee24cc222a629d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6012;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook.display(port=6012, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'experiments\\\\supervised\\\\sl_pytorch_exp_1_small\\\\tboard'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cd experiments\\\\supervised\\\\sl_pytorch_exp_1_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kill' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!kill 10904"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 10944."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs --port 6014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 21808."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir tboard --port 6013\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
